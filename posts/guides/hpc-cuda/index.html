<!doctype html><html><head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge"><title>HPC - CUDA - lunarwhite</title><link rel=icon type=image/png href=favicon/favicon.ico><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="summary for in-class assignments in SDU.">
<meta property="og:image" content>
<meta property="og:title" content="HPC - CUDA">
<meta property="og:description" content="summary for in-class assignments in SDU.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://lunarwhite.github.io/posts/guides/hpc-cuda/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2021-05-02T11:38:49+00:00">
<meta property="article:modified_time" content="2021-05-02T11:38:49+00:00">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="HPC - CUDA">
<meta name=twitter:description content="summary for in-class assignments in SDU.">
<script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script>
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@1,500&display=swap" rel=stylesheet>
<link href="https://fonts.googleapis.com/css2?family=Fira+Sans&display=swap" rel=stylesheet>
<link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel=stylesheet>
<link rel=stylesheet type=text/css media=screen href=https://lunarwhite.github.io/css/main.2295b92014ca185421cf463b4ce4c1bf43322196fcad9519fe35f8e89d36700d.css>
<link disabled id=dark-mode-theme rel=stylesheet href=https://lunarwhite.github.io/css/dark.80b2eb1f37be2454ead72ba0f2662f3022d939734e00b0909a04541420aa9d6c.css>
</head>
<body>
<div class=content><header>
<div class=main>
<a href=https://lunarwhite.github.io/>lunarwhite</a>
</div>
<nav>
<a href=/>Home</a>
<a href=/posts>Posts</a>
<a href=/tags>Tags</a>
<a href=/about>About</a>
/ <a id=dark-mode-toggle><i data-feather=sun></i></a>
</nav>
</header>
<main>
<article>
<div class=title>
<h1 class=title>HPC - CUDA</h1>
<div class=meta>Posted on May 2, 2021</div>
</div>
<section class=body>
<h2 id=1-初识与cuda>1 初识与CUDA</h2>
<h3 id=10-基础概念>1.0 基础概念</h3>
<ul>
<li>主机端-设备端（Host-Device）</li>
<li>内核函数（Kernel Function）</li>
<li>线程模型（Thread Model）</li>
<li>存储模型（Memory Model）</li>
<li>执行模型（CUDA Execution Model）</li>
</ul>
<blockquote>
<p>GPU连接节点 <code>ssh gpu01</code></p>
</blockquote>
<h3 id=11-kernel示例>1.1 kernel示例</h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>VecAdd</span>(<span style=color:#66d9ef>float</span><span style=color:#f92672>*</span> A, <span style=color:#66d9ef>float</span><span style=color:#f92672>*</span> B, <span style=color:#66d9ef>float</span><span style=color:#f92672>*</span> C){
    <span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> threadIdx.x;
    C[i] <span style=color:#f92672>=</span> A[i] <span style=color:#f92672>+</span> B[i];
}

<span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(){
    VecAdd<span style=color:#f92672>&lt;&lt;&lt;</span><span style=color:#ae81ff>1</span>, N<span style=color:#f92672>&gt;&gt;&gt;</span>(A, B, C);
}
</code></pre></div><h3 id=12-线程模型>1.2 线程模型</h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>kernel</span>(<span style=color:#66d9ef>float</span><span style=color:#f92672>*</span> parameter);

dim3 <span style=color:#a6e22e>DimGrid</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>2</span>); <span style=color:#75715e>//6 thread blocks
</span><span style=color:#75715e></span>dim3 <span style=color:#a6e22e>DimBlock</span>(<span style=color:#ae81ff>16</span>, <span style=color:#ae81ff>16</span>); <span style=color:#75715e>//256 threads per block
</span><span style=color:#75715e></span>
kernel<span style=color:#f92672>&lt;&lt;&lt;</span>DimGrid, DimBlock<span style=color:#f92672>&gt;&gt;&gt;</span>(<span style=color:#66d9ef>float</span><span style=color:#f92672>*</span> parameter)
</code></pre></div><h3 id=13-cuda程序框架>1.3 CUDA程序框架</h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>Kernel_First</span>(args){
}

main(){
    cudaMalloc(d_A);
    cudaMemcpy(HostToDevice);
    Kernel_First<span style=color:#f92672>&lt;&lt;&lt;</span>Grid,Block<span style=color:#f92672>&gt;&gt;&gt;</span>(d_A);
    cudaMemcpy(DeviceToHost);
    cudaFree(d_A);
}
</code></pre></div><h3 id=14-简单的数组一一对应相加11>1.4 简单的数组一一对应相加&#171;&lt;1,1&#187;></h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;cuda_runtime.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdio.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&#34;device_launch_parameters.h&#34;</span><span style=color:#75715e>
</span><span style=color:#75715e></span>
__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>add</span>(<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> a, <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> b, <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> c){
    <span style=color:#f92672>*</span>c <span style=color:#f92672>=</span> <span style=color:#f92672>*</span>a <span style=color:#f92672>+</span> <span style=color:#f92672>*</span>b;
}

<span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(){
    <span style=color:#66d9ef>int</span> a, b, c; <span style=color:#75715e>// host copy
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>d_a, <span style=color:#f92672>*</span>d_b, <span style=color:#f92672>*</span>d_c; <span style=color:#75715e>// device copy
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> size <span style=color:#f92672>=</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>);

    <span style=color:#75715e>// allocate for device copy
</span><span style=color:#75715e></span>    cudaMalloc((<span style=color:#66d9ef>void</span> <span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_a, size);
    cudaMalloc((<span style=color:#66d9ef>void</span> <span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_b, size);
    cudaMalloc((<span style=color:#66d9ef>void</span> <span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_c, size);

    <span style=color:#75715e>// setup input values
</span><span style=color:#75715e></span>    a <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>;
    b <span style=color:#f92672>=</span> <span style=color:#ae81ff>7</span>;

    <span style=color:#75715e>// copy inputs to device
</span><span style=color:#75715e></span>    cudaMemcpy(d_a, <span style=color:#f92672>&amp;</span>a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, <span style=color:#f92672>&amp;</span>b, size, cudaMemcpyHostToDevice);

    <span style=color:#75715e>// launch add() kernel on GPU
</span><span style=color:#75715e></span>    add<span style=color:#f92672>&lt;&lt;&lt;</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>1</span><span style=color:#f92672>&gt;&gt;&gt;</span>(d_a, d_b, d_c);

    <span style=color:#75715e>// copy result back to host
</span><span style=color:#75715e></span>    cudaMemcpy(<span style=color:#f92672>&amp;</span>c, d_c, size, cudaMemcpyDeviceToHost) ;

    printf(<span style=color:#e6db74>&#34;c = %d</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, c);

    <span style=color:#75715e>// cleanup
</span><span style=color:#75715e></span>    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);

    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>;
}
</code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>nvcc <span style=color:#ae81ff>4</span><span style=color:#f92672>-</span><span style=color:#ae81ff>1.</span>cu <span style=color:#f92672>-</span>o <span style=color:#ae81ff>4</span><span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>
.<span style=color:#f92672>/</span><span style=color:#ae81ff>4</span><span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>
</code></pre></div><h3 id=15-在-block-上的一一对应的并行n1>1.5 在 block 上的一一对应的并行&#171;&lt;N,1&#187;></h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;cuda_runtime.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdio.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdlib.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&#34;device_launch_parameters.h&#34;</span><span style=color:#75715e>
</span><span style=color:#75715e>#define N 512
</span><span style=color:#75715e></span>
__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>add</span>(<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> a, <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> b, <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> c) {
    c[blockIdx.x] <span style=color:#f92672>=</span> a[blockIdx.x] <span style=color:#f92672>+</span> b[blockIdx.x];
}

<span style=color:#66d9ef>void</span> <span style=color:#a6e22e>random_ints</span>(<span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> a, <span style=color:#66d9ef>int</span> NN) { <span style=color:#75715e>// 返回一个0~10000的数
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> i;
    <span style=color:#66d9ef>for</span>(i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> NN; <span style=color:#f92672>++</span>i)
    a[i] <span style=color:#f92672>=</span> rand()<span style=color:#f92672>%</span><span style=color:#ae81ff>10000</span>;
}

<span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(<span style=color:#66d9ef>void</span>) {
    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>a, <span style=color:#f92672>*</span>b, <span style=color:#f92672>*</span>c;
    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>d_a, <span style=color:#f92672>*</span>d_b, <span style=color:#f92672>*</span>d_c;
    <span style=color:#66d9ef>int</span> size <span style=color:#f92672>=</span> N <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>);

    <span style=color:#75715e>// alloc for device
</span><span style=color:#75715e></span>    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_a, size);
    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_b, size);
    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_c, size);

    <span style=color:#75715e>// alloc for host
</span><span style=color:#75715e></span>    a <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>)malloc(size);
    random_ints(a, N);
    b <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>)malloc(size);
    random_ints(b, N);
    c <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>)malloc(size);

    <span style=color:#75715e>// copy inputs to device
</span><span style=color:#75715e></span>    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);

    <span style=color:#75715e>// launch add() kernel on GPU
</span><span style=color:#75715e></span>    add<span style=color:#f92672>&lt;&lt;&lt;</span>N,<span style=color:#ae81ff>1</span><span style=color:#f92672>&gt;&gt;&gt;</span>(d_a, d_b, d_c);

    <span style=color:#75715e>// copy result back to host
</span><span style=color:#75715e></span>    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);

    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;i <span style=color:#f92672>&lt;</span> N;i<span style=color:#f92672>++</span>)
        printf(<span style=color:#e6db74>&#34;c[%d] = %d</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, i, c[i]);

    <span style=color:#75715e>// cleanup
</span><span style=color:#75715e></span>    free(a);
    free(b);
    free(c);
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);

    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>;
}
</code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>nvcc <span style=color:#ae81ff>4</span><span style=color:#f92672>-</span><span style=color:#ae81ff>2.</span>cu <span style=color:#f92672>-</span>o <span style=color:#ae81ff>4</span><span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>
.<span style=color:#f92672>/</span><span style=color:#ae81ff>4</span><span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>
</code></pre></div><h3 id=16-把block细分为一组并行的threads1n>1.6 把block细分为一组并行的threads&#171;&lt;1,N&#187;></h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;cuda_runtime.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdio.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdlib.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&#34;device_launch_parameters.h&#34;</span><span style=color:#75715e>
</span><span style=color:#75715e>#define N 512
</span><span style=color:#75715e></span>
__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>add</span>(<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>a, <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>b, <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>c) {
    c[threadIdx.x] <span style=color:#f92672>=</span> a[threadIdx.x] <span style=color:#f92672>+</span> b[threadIdx.x];
}

<span style=color:#66d9ef>void</span> <span style=color:#a6e22e>random_ints</span>(<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>a, <span style=color:#66d9ef>int</span> NN) {
    <span style=color:#66d9ef>int</span> i;
    <span style=color:#66d9ef>for</span>(i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> NN; <span style=color:#f92672>++</span>i)
    a[i] <span style=color:#f92672>=</span> rand()<span style=color:#f92672>%</span><span style=color:#ae81ff>10000</span>;
}

<span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(<span style=color:#66d9ef>void</span>) {
    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>a, <span style=color:#f92672>*</span>b, <span style=color:#f92672>*</span>c;
    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>d_a, <span style=color:#f92672>*</span>d_b, <span style=color:#f92672>*</span>d_c;
    <span style=color:#66d9ef>int</span> size <span style=color:#f92672>=</span> N <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>);

    <span style=color:#75715e>// alloc for device
</span><span style=color:#75715e></span>    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_a, size);
    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_b, size);
    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_c, size);

    <span style=color:#75715e>// alloc for host
</span><span style=color:#75715e></span>    a <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>)malloc(size); random_ints(a, N);
    b <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>)malloc(size); random_ints(b, N);
    c <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>)malloc(size);

    <span style=color:#75715e>// copy inputs to device
</span><span style=color:#75715e></span>    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);

    <span style=color:#75715e>// launch add() kernel on GPU
</span><span style=color:#75715e></span>    add<span style=color:#f92672>&lt;&lt;&lt;</span><span style=color:#ae81ff>1</span>,N<span style=color:#f92672>&gt;&gt;&gt;</span>(d_a, d_b, d_c);

    <span style=color:#75715e>// copy result back to host
</span><span style=color:#75715e></span>    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);

    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;i <span style=color:#f92672>&lt;</span> N;i<span style=color:#f92672>++</span>)
        printf(<span style=color:#e6db74>&#34;c[%d] = %d</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, i, c[i]);

    <span style=color:#75715e>// cleanup
</span><span style=color:#75715e></span>    free(a);
    free(b);
    free(c);
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);

    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>;
}
</code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>nvcc <span style=color:#ae81ff>4</span><span style=color:#f92672>-</span><span style=color:#ae81ff>3.</span>cu <span style=color:#f92672>-</span>o <span style=color:#ae81ff>4</span><span style=color:#f92672>-</span><span style=color:#ae81ff>3</span>
.<span style=color:#f92672>/</span><span style=color:#ae81ff>4</span><span style=color:#f92672>-</span><span style=color:#ae81ff>3</span>
</code></pre></div><h3 id=17-block和threads结合使用>1.7 block和threads结合使用</h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;cuda_runtime.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdio.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdlib.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&#34;device_launch_parameters.h&#34;</span><span style=color:#75715e>
</span><span style=color:#75715e>#define N (2048*2048)
</span><span style=color:#75715e>#define THREADS_PER_BLOCK 512
</span><span style=color:#75715e></span>
__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>add</span>(<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>a, <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>b, <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>c) {
    <span style=color:#66d9ef>int</span> index <span style=color:#f92672>=</span> threadIdx.x <span style=color:#f92672>+</span> blockIdx.x <span style=color:#f92672>*</span> blockDim.x;
    c[index] <span style=color:#f92672>=</span> a[index] <span style=color:#f92672>+</span> b[index];
}

<span style=color:#66d9ef>void</span> <span style=color:#a6e22e>random_ints</span>(<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>a, <span style=color:#66d9ef>int</span> NN) {
    <span style=color:#66d9ef>int</span> i;
    <span style=color:#66d9ef>for</span>(i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> NN; <span style=color:#f92672>++</span>i)
        a[i] <span style=color:#f92672>=</span> rand()<span style=color:#f92672>%</span><span style=color:#ae81ff>10000</span>;
}

<span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(<span style=color:#66d9ef>void</span>) {
    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>a, <span style=color:#f92672>*</span>b, <span style=color:#f92672>*</span>c;
    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>d_a, <span style=color:#f92672>*</span>d_b, <span style=color:#f92672>*</span>d_c;
    <span style=color:#66d9ef>int</span> size <span style=color:#f92672>=</span> N <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>);

    <span style=color:#75715e>// alloc for device
</span><span style=color:#75715e></span>    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_a, size);
    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_b, size);
    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_c, size);

    <span style=color:#75715e>// alloc for host
</span><span style=color:#75715e></span>    a <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>)malloc(size); random_ints(a, N);
    b <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>)malloc(size); random_ints(b, N);
    c <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>)malloc(size);

    <span style=color:#75715e>// copy inputs to device
</span><span style=color:#75715e></span>    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);

    <span style=color:#75715e>// launch add() kernel on GPU
</span><span style=color:#75715e></span>    add<span style=color:#f92672>&lt;&lt;&lt;</span>N<span style=color:#f92672>/</span>THREADS_PER_BLOCK,THREADS_PER_BLOCK<span style=color:#f92672>&gt;&gt;&gt;</span>(d_a, d_b, d_c);

    <span style=color:#75715e>// copy result back to host
</span><span style=color:#75715e></span>    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);

    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;i <span style=color:#f92672>&lt;</span> N;i<span style=color:#f92672>++</span>)
        printf(<span style=color:#e6db74>&#34;c[%d] = %d</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, i, c[i]);

    <span style=color:#75715e>// cleanup
</span><span style=color:#75715e></span>    free(a);
    free(b);
    free(c);
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);

    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>;
}
</code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>nvcc <span style=color:#ae81ff>4</span><span style=color:#f92672>-</span><span style=color:#ae81ff>4.</span>cu <span style=color:#f92672>-</span>o <span style=color:#ae81ff>4</span><span style=color:#f92672>-</span><span style=color:#ae81ff>4</span>
.<span style=color:#f92672>/</span><span style=color:#ae81ff>4</span><span style=color:#f92672>-</span><span style=color:#ae81ff>4</span>
</code></pre></div><h2 id=2-cuda微进阶>2 CUDA微进阶</h2>
<h3 id=21-纯-cpu-加法>2.1 纯 CPU 加法</h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdio.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#define N 4
</span><span style=color:#75715e></span>
<span style=color:#66d9ef>void</span> <span style=color:#a6e22e>add_cpu</span>(<span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>a, <span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>b, <span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>c, <span style=color:#66d9ef>int</span> NN){
    <span style=color:#66d9ef>int</span> idx <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
    <span style=color:#66d9ef>for</span>(idx <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; idx<span style=color:#f92672>&lt;</span>NN; idx<span style=color:#f92672>++</span>)
        c[idx] <span style=color:#f92672>=</span> a[idx] <span style=color:#f92672>+</span> b[idx];
}

<span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(){
    <span style=color:#66d9ef>float</span> a[N]<span style=color:#f92672>=</span>{<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>};
    <span style=color:#66d9ef>float</span> b[N]<span style=color:#f92672>=</span>{<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>};
    <span style=color:#66d9ef>float</span> c[N]<span style=color:#f92672>=</span>{<span style=color:#ae81ff>0</span>};
    add_cpu(<span style=color:#f92672>&amp;</span>a, <span style=color:#f92672>&amp;</span>b, <span style=color:#f92672>&amp;</span>c, N);

    <span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
    <span style=color:#66d9ef>for</span>(i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;i <span style=color:#f92672>&lt;</span> N;i<span style=color:#f92672>++</span>)
        printf(<span style=color:#e6db74>&#34;c[%d] = %f</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, i, c[i]);

    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>;
}
</code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>gcc <span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>1</span><span style=color:#f92672>-</span>c.c <span style=color:#f92672>-</span>o <span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>1</span><span style=color:#f92672>-</span>c
.<span style=color:#f92672>/</span><span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>1</span><span style=color:#f92672>-</span>c
</code></pre></div><h3 id=21-纯-cuda-加法>2.1 纯 CUDA 加法</h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;cuda_runtime.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdio.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&#34;device_launch_parameters.h&#34;</span><span style=color:#75715e>
</span><span style=color:#75715e></span>
<span style=color:#75715e>#define N 4
</span><span style=color:#75715e></span>
__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>add_gpu</span>(<span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>a, <span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>b, <span style=color:#66d9ef>int</span> NN) {
    <span style=color:#66d9ef>int</span> idx <span style=color:#f92672>=</span>blockIdx.x<span style=color:#f92672>*</span> blockDim.x<span style=color:#f92672>+</span> threadIdx.x;
    <span style=color:#66d9ef>if</span> (idx <span style=color:#f92672>&lt;</span> NN)
        a[idx] <span style=color:#f92672>+=</span> b[idx];
}

<span style=color:#66d9ef>void</span> <span style=color:#a6e22e>random_ints</span>(<span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>a, <span style=color:#66d9ef>int</span> NN) {
    <span style=color:#66d9ef>int</span> i;
    <span style=color:#66d9ef>for</span> (i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> NN; <span style=color:#f92672>++</span>i)
        a[i] <span style=color:#f92672>=</span> rand() <span style=color:#f92672>/</span> (<span style=color:#66d9ef>double</span>)(RAND_MAX <span style=color:#f92672>/</span> <span style=color:#ae81ff>100</span>);
}

<span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>() {
    <span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>a, <span style=color:#f92672>*</span>b;
    <span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>d_a, <span style=color:#f92672>*</span>d_b;
    <span style=color:#66d9ef>int</span> size <span style=color:#f92672>=</span> N <span style=color:#f92672>*</span> <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>);

    <span style=color:#75715e>// alloc for device
</span><span style=color:#75715e></span>    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_a, size);
    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_b, size);

    <span style=color:#75715e>// alloc for host
</span><span style=color:#75715e></span>    a <span style=color:#f92672>=</span> (<span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>)malloc(size); random_ints(a, N);
    b <span style=color:#f92672>=</span> (<span style=color:#66d9ef>float</span> <span style=color:#f92672>*</span>)malloc(size); random_ints(b, N);

    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> N; i<span style=color:#f92672>++</span>) {
        printf(<span style=color:#e6db74>&#34;a[%d] = %f&#34;</span>, i, a[i]);
        printf(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\t</span><span style=color:#e6db74>b[%d] = %f</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, i, b[i]);
    }

    <span style=color:#75715e>// copy inputs to device
</span><span style=color:#75715e></span>    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);

    dim3 dimBlock (<span style=color:#ae81ff>512</span>);
    dim3 dimGrid( ceil( N <span style=color:#f92672>/</span> <span style=color:#ae81ff>512</span> ));

    <span style=color:#75715e>// launch add() kernel on GPU
</span><span style=color:#75715e></span>    add_gpu<span style=color:#f92672>&lt;&lt;&lt;</span>dimGrid, dimBlock<span style=color:#f92672>&gt;&gt;&gt;</span>(d_a, d_b, N);

    <span style=color:#75715e>// copy result back to host
</span><span style=color:#75715e></span>    cudaMemcpy(a, d_a, size, cudaMemcpyDeviceToHost);

    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> N; i<span style=color:#f92672>++</span>) {
        printf(<span style=color:#e6db74>&#34;a[%d] = %f</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, i, a[i]);
    }

    <span style=color:#75715e>// cleanup
</span><span style=color:#75715e></span>    free(a);
    free(b);
    cudaFree(d_a);
    cudaFree(d_b);

    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>;
}
</code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>nvcc <span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>1</span><span style=color:#f92672>-</span>cu.cu <span style=color:#f92672>-</span>o <span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>1</span><span style=color:#f92672>-</span>cu
.<span style=color:#f92672>/</span><span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>1</span><span style=color:#f92672>-</span>cu
</code></pre></div><h2 id=22-unified-memory>2.2 unified-memory</h2>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;cuda_runtime.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdio.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&#34;device_launch_parameters.h&#34;</span><span style=color:#75715e>
</span><span style=color:#75715e></span>
<span style=color:#75715e>#define N 10*10
</span><span style=color:#75715e></span>
__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>AplusB</span>(<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>ret, <span style=color:#66d9ef>int</span> a, <span style=color:#66d9ef>int</span> b) {
    ret[threadIdx.x] <span style=color:#f92672>=</span> a <span style=color:#f92672>+</span> b <span style=color:#f92672>+</span> threadIdx.x;
}

<span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(){
    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>ret;
    cudaMallocManaged(<span style=color:#f92672>&amp;</span>ret, N<span style=color:#f92672>*</span><span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>));

    AplusB<span style=color:#f92672>&lt;&lt;&lt;</span><span style=color:#ae81ff>1</span>,N<span style=color:#f92672>&gt;&gt;&gt;</span>(ret, <span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>100</span>);

    cudaDeviceSynchronize();

    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>; i<span style=color:#f92672>&lt;</span>N; i<span style=color:#f92672>++</span>)
        printf(<span style=color:#e6db74>&#34;%d: A+B= %d</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, i, ret[i]);

    cudaFree(ret);
    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>;
}
</code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>nvcc <span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>2.</span>cu <span style=color:#f92672>-</span>o <span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>
.<span style=color:#f92672>/</span><span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>
</code></pre></div><h3 id=23-gpu-declared_managed_variable>2.3 GPU-declared_managed_variable</h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;cuda_runtime.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdio.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&#34;device_launch_parameters.h&#34;</span><span style=color:#75715e>
</span><span style=color:#75715e></span>
<span style=color:#75715e>#define N 10*10
</span><span style=color:#75715e></span>
__device__ __managed__ <span style=color:#66d9ef>int</span> ret[<span style=color:#ae81ff>1000</span>];
__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>AplusB</span>(<span style=color:#66d9ef>int</span> a, <span style=color:#66d9ef>int</span> b){
    ret[threadIdx.x] <span style=color:#f92672>=</span> a <span style=color:#f92672>+</span> b <span style=color:#f92672>+</span> threadIdx.x;
}
<span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(){
    AplusB<span style=color:#f92672>&lt;&lt;&lt;</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1000</span><span style=color:#f92672>&gt;&gt;&gt;</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>100</span>);

    cudaDeviceSynchronize();

    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>1000</span>; i<span style=color:#f92672>++</span>)
        printf(<span style=color:#e6db74>&#34;%d: A+B= %d</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, i, ret[i]);

    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>;
}
</code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>nvcc <span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>3.</span>cu <span style=color:#f92672>-</span>o <span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>3</span>
.<span style=color:#f92672>/</span><span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>3</span>
</code></pre></div><h3 id=24-矩阵乘法>2.4 矩阵乘法</h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#75715e>#include</span> <span style=color:#75715e>&#34;cuda_runtime.h&#34;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&#34;device_launch_parameters.h&#34;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdio.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#define Row  126
</span><span style=color:#75715e>#define Col 250
</span><span style=color:#75715e></span>
__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>matrix_mul_gpu</span>(<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>M, <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> N, <span style=color:#66d9ef>int</span><span style=color:#f92672>*</span> P, <span style=color:#66d9ef>int</span> width) {
    <span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> threadIdx.x <span style=color:#f92672>+</span> blockDim.x <span style=color:#f92672>*</span> blockIdx.x;
    <span style=color:#66d9ef>int</span> j <span style=color:#f92672>=</span> threadIdx.y <span style=color:#f92672>+</span> blockDim.y <span style=color:#f92672>*</span> blockIdx.y;

    <span style=color:#66d9ef>int</span> sum <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> k<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>;k<span style=color:#f92672>&lt;</span>width;k<span style=color:#f92672>++</span>) {
        <span style=color:#66d9ef>int</span> a <span style=color:#f92672>=</span> M[j<span style=color:#f92672>*</span>width<span style=color:#f92672>+</span>k];
        <span style=color:#66d9ef>int</span> b <span style=color:#f92672>=</span> N[k<span style=color:#f92672>*</span>width<span style=color:#f92672>+</span>i];
        sum <span style=color:#f92672>+=</span> a<span style=color:#f92672>*</span>b;
    }
    P[j<span style=color:#f92672>*</span>width<span style=color:#f92672>+</span>i] <span style=color:#f92672>=</span> sum;
}

<span style=color:#66d9ef>int</span> <span style=color:#a6e22e>main</span>(){
    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>d_dataA, <span style=color:#f92672>*</span>d_dataB, <span style=color:#f92672>*</span>d_dataC;

    <span style=color:#75715e>// alloc for host
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>A <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>)malloc(<span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span> Row <span style=color:#f92672>*</span> Col);
    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>B <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>)malloc(<span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span> Row <span style=color:#f92672>*</span> Col);
    <span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>C <span style=color:#f92672>=</span> (<span style=color:#66d9ef>int</span> <span style=color:#f92672>*</span>)malloc(<span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span> Row <span style=color:#f92672>*</span> Col);

    <span style=color:#75715e>// alloc for device
</span><span style=color:#75715e></span>    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_dataA, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span>Row<span style=color:#f92672>*</span>Col);
    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_dataB, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span>Row<span style=color:#f92672>*</span>Col);
    cudaMalloc((<span style=color:#66d9ef>void</span><span style=color:#f92672>**</span>)<span style=color:#f92672>&amp;</span>d_dataC, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span>Row<span style=color:#f92672>*</span>Col);

    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> Row<span style=color:#f92672>*</span>Col; i<span style=color:#f92672>++</span>) {
        A[i] <span style=color:#f92672>=</span> <span style=color:#ae81ff>90</span>;
        B[i] <span style=color:#f92672>=</span> <span style=color:#ae81ff>10</span>;
    }

    <span style=color:#75715e>// copy inputs to device
</span><span style=color:#75715e></span>    cudaMemcpy(d_dataA, A, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span> Row <span style=color:#f92672>*</span> Col, cudaMemcpyHostToDevice);
    cudaMemcpy(d_dataB, B, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span> Row <span style=color:#f92672>*</span> Col, cudaMemcpyHostToDevice);

    dim3 threadPerBlock(<span style=color:#ae81ff>16</span>, <span style=color:#ae81ff>16</span>);
    dim3 blockNumber((Col<span style=color:#f92672>+</span>threadPerBlock.x<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>/</span> threadPerBlock.x, (Row<span style=color:#f92672>+</span>threadPerBlock.y<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>/</span> threadPerBlock.y );

    printf(<span style=color:#e6db74>&#34;Block(%d,%d)   Grid(%d,%d).</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, threadPerBlock.x, threadPerBlock.y, blockNumber.x, blockNumber.y);
    matrix_mul_gpu <span style=color:#f92672>&lt;&lt;</span> <span style=color:#f92672>&lt;</span>blockNumber, threadPerBlock <span style=color:#f92672>&gt;&gt;</span> <span style=color:#f92672>&gt;</span> (d_dataA, d_dataB, d_dataC, Col);

    <span style=color:#75715e>// copy result back to host
</span><span style=color:#75715e></span>    cudaMemcpy(C, d_dataC, <span style=color:#66d9ef>sizeof</span>(<span style=color:#66d9ef>int</span>) <span style=color:#f92672>*</span> Row <span style=color:#f92672>*</span> Col, cudaMemcpyDeviceToHost);

    <span style=color:#75715e>// cleanup
</span><span style=color:#75715e></span>    free(A);
    free(B);
    free(C);
    cudaFree(d_dataA);
    cudaFree(d_dataB);
    cudaFree(d_dataC);

    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span>;
}
</code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>nvcc <span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>4.</span>cu <span style=color:#f92672>-</span>o <span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>4</span>
.<span style=color:#f92672>/</span><span style=color:#ae81ff>5</span><span style=color:#f92672>-</span><span style=color:#ae81ff>4</span>
</code></pre></div>
</section>
<div class=post-tags>
<nav class="nav tags">
<ul class=tags>
<li><a href=/tags/self-tutorial>self-tutorial</a></li>
<li><a href=/tags/high-performance-computing>high-performance-computing</a></li>
</ul>
</nav>
</div>
</article>
</main>
<footer>
<hr><a class=soc href=https://www.linkedin.com/in/yuedongwoo/ title=LinkedIn><i data-feather=linkedin></i></a>|<a class=soc href=https://github.com/lunarwhite title=GitHub><i data-feather=github></i></a>|<a class=soc href title=Twitter><i data-feather=twitter></i></a>|<a class=soc href title=Instagram><i data-feather=instagram></i></a>|<a class=soc href title=Bilibili><i data-feather=tv></i></a>|<a class=soc href=https://www.zhihu.com/people/wydnlz title=Zhihu><i data-feather=link></i></a>|⚡️
2021 © lunarwhite | <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a>
</footer>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','G-80H8N7NN50','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<script src=https://lunarwhite.github.io/js/toggle.dark.js></script>
<script>feather.replace()</script>
<script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$']],processEscapes:!0,processEnvironments:!0,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var b=MathJax.Hub.getAllJax(),a;for(a=0;a<b.length;a+=1)b[a].SourceElement().parentNode.className+=' has-jax'}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script></div>
</body>
</html>